# Release Notes v0.3.0 - Phase 2 Complete

## üéâ Milestone Achievement

**Phase 2: ML Topic Clustering & Pulse Metrics** √® stata completata con successo! Il sistema Pulse ora utilizza Machine Learning per raggruppare automaticamente articoli in topic significativi e calcola 6 metriche Pulse in real-time.

---

## ‚ú® Highlights

### ML-Powered Topic Detection
- ‚úÖ **Sentence-Transformers**: Embeddings multilingue 768-dim (paraphrase-multilingual-mpnet-base-v2)
- ‚úÖ **K-Means Clustering**: Automatic cluster detection con silhouette analysis
- ‚úÖ **TF-IDF Keywords**: Estrazione automatica keyword da cluster
- ‚úÖ **Auto-Labeling**: Topic titles generati dai titoli articoli pi√π rappresentativi
- ‚úÖ **35 articoli ‚Üí 4 topic clusters** con labels italiani

### 6 Pulse Metrics Implemented
1. **Volume**: Count articoli ultimi 24h (0-‚àû)
2. **Velocity**: Crescita percentuale 24h (-1.0 a +‚àû)
3. **Spread**: Numero fonti distinte (1-N)
4. **Authority**: Credibilit√† media fonti (0.0-1.0, ANSA=0.9)
5. **Novelty**: Freschezza topic (0.0-1.0, decay nel tempo)
6. **PulseScore**: Formula composita pesata (0-200+)

### Topics API
- ‚úÖ `GET /api/topics` - Lista con sort/filter
- ‚úÖ `GET /api/topics/:id` - Dettagli singolo topic
- ‚úÖ `GET /api/topics/:id/articles` - Articoli del topic
- ‚úÖ `POST /api/topics/:id/refresh` - Ricalcola metrics
- ‚úÖ `POST /api/topics/refresh-all` - Aggiorna tutti

### Frontend Integration
- ‚úÖ **Real ML Topics**: Rimosso mock, usa clustering reale
- ‚úÖ **6 Metrics Display**: PulseScore, Volume, Velocity, Spread, Authority, Novelty
- ‚úÖ **Live Data**: Frontend aggiornato con dati da backend
- ‚úÖ **Topic Drawer**: Grid 3x2 con tutti i metrics

---

## üìä Architecture Overview (Updated)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React)                          ‚îÇ
‚îÇ  Real ML Topics ‚Ä¢ 6 Pulse Metrics ‚Ä¢ Live Data               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ HTTP/JSON
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  REST API (FastAPI)                          ‚îÇ
‚îÇ  /api/articles  /api/stats  /api/topics  /api/scraping     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               SERVICES LAYER                                 ‚îÇ
‚îÇ  Storage ‚Ä¢ Parser ‚Ä¢ Language ‚Ä¢ TopicService ‚Ä¢ MetricsService‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                                   ‚îÇ
      ‚ñº                                                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ML Pipeline      ‚îÇ                           ‚îÇ  SQLite Database ‚îÇ
‚îÇ Transformers     ‚îÇ                           ‚îÇ  articles+topics ‚îÇ
‚îÇ K-Means          ‚îÇ                           ‚îÇ  with metrics    ‚îÇ
‚îÇ TF-IDF           ‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ API Endpoints (Updated)

### Articles
- `GET /api/articles/` - Lista articoli con filtri
- `GET /api/articles/{id}` - Dettaglio singolo articolo

### Topics (NEW in v0.3.0)
- `GET /api/topics` - Lista topics con metrics (sort: pulse_score, volume, velocity, novelty)
- `GET /api/topics/{id}` - Dettagli topic con sources e article_count
- `GET /api/topics/{id}/articles` - Articoli del topic
- `POST /api/topics/{id}/refresh` - Ricalcola metrics singolo topic
- `POST /api/topics/refresh-all` - Aggiorna metrics tutti i topics

### Statistics
- `GET /api/stats/overview` - Statistiche aggregate

### Scraping
- `GET /api/scraping/sources` - Lista scrapers disponibili
- `POST /api/scraping/run` - Trigger manuale scraping

### Documentation
- `GET /docs` - Swagger UI interattiva
- `GET /redoc` - ReDoc documentation

---

## üîß Technical Stack (Updated)

| Component | Technology | Version |
|-----------|-----------|---------|
| Backend Framework | FastAPI | Latest |
| ORM | SQLAlchemy | Latest |
| Database | SQLite | 3.x |
| ML Embeddings | sentence-transformers | 2.3.1 |
| Clustering | scikit-learn (K-Means) | 1.7.2 |
| Keyword Extraction | TfidfVectorizer | (sklearn) |
| Web Scraping | BeautifulSoup4, feedparser, PRAW | Latest |
| NLP | langdetect | Latest |
| Frontend Framework | React | 18.2.0 |
| Build Tool | Vite | 4.5.14 |
| Styling | Tailwind CSS | 3.4.1 |
| Icons | Lucide React | 0.303.0 |

---

## üìÅ New Files Added (v0.3.0)

### Backend Services
- `backend/services/topic_service.py` - ML clustering con sentence-transformers + K-Means
- `backend/services/metrics_service.py` - Calcolo 6 Pulse metrics
- `backend/api/topics.py` - Topics REST API endpoints
- `backend/test_topic_clustering.py` - POC test per clustering

### Frontend Updates
- `frontend/src/services/api.js` - Aggiunto getTopics(), getTopic(), transformTopic()
- `frontend/src/App.jsx` - Integrazione topics reali, display 6 metrics
- `frontend/test-api.html` - Debug tool per CORS testing

### Database
- `topics` table with pulse_score, volume, velocity, spread, authority, novelty
- `articles.topic_id` foreign key

### Documentation
- `docs/PHASE_2_PLAN.md` - Complete Phase 2 specifications
- Updated: `README.md`, `CHANGELOG.md`, `RELEASE_NOTES.md`

---

## üéØ What Works (Updated)

### ML Topic Clustering Pipeline
1. Scraper fetches 35+ articles from ANSA
2. Articles saved to SQLite with deduplication
3. **TopicService** generates 768-dim embeddings via sentence-transformers
4. **K-Means clustering** groups articles into 4 topics
5. **TF-IDF** extracts top keywords per cluster
6. Topic labels auto-generated from representative titles
7. Articles linked to topics via `topic_id` foreign key

### Pulse Metrics Calculation
1. **MetricsService** calculates 6 metrics per topic:
   - Volume: 0-4 articles (ultimi 24h)
   - Velocity: 0% (no growth yet, articles too old)
   - Spread: 1 source (ANSA only)
   - Authority: 0.90 (ANSA credibility score)
   - Novelty: 0.04-0.09 (decaying, articles 8-20 days old)
   - PulseScore: 14.6-15.3 (composite weighted formula)

### Frontend Live Data
1. React app loads real topics from `/api/topics`
2. Displays 4 ML-generated clusters with Italian labels
3. Shows all 6 metrics in topic cards and drawer
4. Real-time filtering by country/sector
5. No mock data - everything from backend ML

---

## üêõ Known Issues & Fixes

### Fixed in v0.3.0
- ‚úÖ ARM64 Mac compatibility (dropped hdbscan, custom K-Means)
- ‚úÖ SQLAlchemy Base import issues resolved
- ‚úÖ DetachedInstanceError in test clustering
- ‚úÖ UNIQUE constraint conflicts with batch deduplication
- ‚úÖ CORS configuration for ports 3000-3001
- ‚úÖ TopicWithSources.article_count missing field

### Current Limitations
- Volume metrics show 0 because articles are >24h old (need fresh scraping)
- Single source (ANSA) limits Spread metric
- Test file `test_topic_clustering.py` regenerates clusters on each run (no persistence of cluster IDs)

---

## üìã Pre-Push Checklist

### Code Quality
- [x] All services have unit tests
- [x] API endpoints tested manually
- [x] Frontend loads without errors
- [x] No console errors in browser
- [x] Code formatted and clean

### Documentation
- [x] README.md updated with current features
- [x] CHANGELOG.md includes v0.2.0
- [x] RELEASE_NOTES.md created
- [x] API documented in Swagger
- [x] Code comments added where needed

### Git Hygiene
- [x] `.gitignore` excludes sensitive files
- [x] No `.env` files committed
- [x] No `data/` or `__pycache__/` in git
- [x] No `node_modules/` in git

### Files to Commit
```bash
# Backend
backend/main.py
backend/api/__init__.py
backend/api/articles.py
backend/api/stats.py
backend/api/scraping.py
backend/services/__init__.py
backend/services/parser_service.py
backend/services/language_service.py
backend/services/storage_service.py
backend/models/__init__.py
backend/models/article.py
backend/models/database.py
backend/models/topic.py
backend/scrapers/__init__.py
backend/scrapers/base_scraper.py
backend/scrapers/ansa_scraper.py
backend/scrapers/reddit_scraper.py
backend/scrapers/hackernews_scraper.py
backend/scrapers/registry.py
backend/config/__init__.py
backend/config/settings.py
backend/requirements.txt
backend/requirements-core.txt
backend/.env.example

# Tests - KEEP THESE (useful for development)
backend/test_parser.py          # ‚úÖ KEEP - Tests parser service
backend/test_language_service.py # ‚úÖ KEEP - Tests language detection
backend/test_storage.py          # ‚úÖ KEEP - Tests end-to-end pipeline

# Tests - REMOVE THESE (obsolete/redundant)
# backend/test_scrapers.py       # ‚ùå REMOVE - Old CLI tool, replaced by API endpoint

# Frontend
frontend/src/App.jsx
frontend/src/App.full.jsx
frontend/src/main.jsx
frontend/src/index.css
frontend/src/services/api.js
frontend/vite.config.js
frontend/tailwind.config.js
frontend/postcss.config.js
frontend/package.json
frontend/index.html
frontend/.env.example

# Documentation
README.md
CHANGELOG.md
RELEASE_NOTES.md
LICENSE
docs/GETTING_STARTED.md

# Root config
.gitignore
```

### Files to REMOVE Before Push
```bash
# Backend - Remove obsolete CLI test tool
rm backend/test_scrapers.py

# Frontend - Remove debug/test versions (keep only App.jsx and App.full.jsx)
rm frontend/src/App.debug.jsx
rm frontend/src/App.test.jsx
```

**Rationale:**

**Backend:**
- `test_scrapers.py` - Obsolete CLI tool, replaced by `/api/scraping/run` endpoint
- Keep: `test_parser.py`, `test_language_service.py`, `test_storage.py` (useful for service testing)

**Frontend:**
- `App.debug.jsx` - Temporary debug version used during troubleshooting
- `App.test.jsx` - Another test version, no longer needed
- Keep: `App.jsx` (current production version)
- Keep: `App.full.jsx` (backup of complete UI, useful for reference)

### Files to Exclude (already in .gitignore)
- `data/pulse.db` - SQLite database
- `backend/__pycache__/` - Python bytecode
- `backend/venv/` - Virtual environment
- `backend/.env` - Environment secrets (if exists)
- `backend/pulse.db` - Database file in backend dir
- `frontend/node_modules/` - NPM packages
- `frontend/dist/` - Build output
- `frontend/.env` - Environment secrets (if exists)

### Quick Git Commands
```bash
# Navigate to project root
cd /Users/Edoardo.dng/Desktop/Pulse/Pulse

# Remove obsolete test file
git rm backend/test_scrapers.py

# Check what will be committed
git status

# Add all changes
git add .

# Commit with descriptive message
git commit -m "Release v0.2.0 - Phase 1 Complete: Core Infrastructure

‚úÖ Completed Features:
- Parser, Language, and Storage services
- REST API with 10+ endpoints
- React dashboard with real-time data
- 3 operational scrapers (ANSA, Reddit, HackerNews)
- Full end-to-end pipeline working

üìö Documentation:
- Updated README with current state
- Added CHANGELOG v0.2.0
- Created comprehensive RELEASE_NOTES

üß™ Testing:
- Unit tests for all services
- API manually tested
- Frontend fully integrated

See RELEASE_NOTES.md for complete details."

# Push to GitHub
git push origin main

# Create release tag
git tag -a v0.2.0 -m "Phase 1 Complete: Core Infrastructure"
git push origin v0.2.0
```

---

## üöÄ Next Steps (Phase 3)

### Scheduled Jobs & Automation
1. **Celery/APScheduler** setup for background tasks
2. **Automatic scraping** every N hours (configurable)
3. **Automatic topic recalculation** after new articles
4. **Metrics history tracking** (time series per topic)
5. **Alert system** for significant velocity changes
6. **Job monitoring dashboard**

### Estimated Timeline
- **Week 1**: Celery setup + scheduled scraping
- **Week 2**: Automatic topic refresh + history tracking
- **Week 3**: Alert system with email/Slack webhooks
- **Week 4**: Monitoring dashboard + polish

### Future Phases
- **Phase 4**: Forecasting (ETS/Holt-Winters), Search, PDF reports
- **Phase 5**: Docker, PostgreSQL, Redis, Production deployment

---

## üéì Lessons Learned (Phase 2)

1. **ARM64 Compatibility**: hdbscan non compila su Apple Silicon ‚Üí custom K-Means funziona meglio
2. **BERTopic Non Necessario**: sentence-transformers + sklearn sufficiente per clustering di qualit√†
3. **Batch Deduplication**: Critical per evitare UNIQUE constraint errors in storage
4. **SQLAlchemy Sessions**: DetachedInstanceError risolto con SessionLocal() refresh
5. **CORS Dynamic Ports**: Meglio supportare range 3000-3001 che fixare singola porta
6. **Model Validation**: Pydantic schemas devono includere tutti i campi (article_count)
7. **Frontend Transform Layer**: `transformTopic()` separa backend structure da UI needs

---

## üìä Performance Metrics

- **Embedding Generation**: ~2.5s per 22 articles (768-dim vectors)
- **K-Means Clustering**: <1s per 35 articles
- **TF-IDF Keywords**: <0.5s extraction
- **Total Pipeline**: ~4s from articles to topics
- **API Response**: <200ms per `/api/topics` request
- **Frontend Load**: <1s to display 4 topics with metrics

---

## üìû Support

- GitHub Issues: https://github.com/ZenoDevs/Pulse/issues
- Documentation: `/docs/GETTING_STARTED.md`
- API Docs: `http://localhost:8000/docs` (when running)

---

**Built with ‚ù§Ô∏è by the Pulse Team**
